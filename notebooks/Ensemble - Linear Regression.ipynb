{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import label_ranking_average_precision_score as LRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 5000\n",
    "NUM_CLASSES = 3993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get true predictions\n",
    "y_val = pd.read_csv(\"../data/expanded/dev_labels.csv\", names=range(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 3993)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree\n",
    "y_rf = pd.read_csv(\"../public_data/saved_rf_probabilities.csv\", names=range(NUM_CLASSES),header= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5604580391775857"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rf = LRAP(y_val,y_rf)\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "y_knn = pd.read_csv(\"../public_data/knn.csv\", names=range(NUM_CLASSES),header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2912844932011161"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_knn = LRAP(y_val,y_knn)\n",
    "score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "y_svm = pd.read_csv(\"../public_data/svm.csv\", names=range(NUM_CLASSES), header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3391564618701288"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_svm = LRAP(y_val,y_svm)\n",
    "score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN\n",
    "from numpy import load\n",
    "y_nn = pd.read_csv('../public_data/nn_ensemble.csv', names=range(NUM_CLASSES), header = 0)\n",
    "y_nn = np.array(y_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 3993)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1314, 1313]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-7d65a80529b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRAP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_nn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore_nn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mlabel_ranking_average_precision_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m     \"\"\"\n\u001b[1;32m--> 858\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1314, 1313]"
     ]
    }
   ],
   "source": [
    "score_nn = LRAP(y_val,y_nn)\n",
    "score_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f049af8f9b2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import label_ranking_average_precision_score as LRAP\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a convex combination based upon validation scores\n",
    "#Note convex combination does not seem to work the best.\n",
    "total = score_rf + score_knn + score_svm + score_mlp\n",
    "\n",
    "rf_w = score_rf / total\n",
    "knn_w = score_knn / total\n",
    "svm_w = score_svm/total\n",
    "mlp_w = score_nn/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use convex combination or set manually.\n",
    "#ensemble = 0.8*y_rf.values + 0.19*y_svm.values +0.01*y_knn.values\n",
    "ensemble = 0.85*y_nn + 0.127*y_rf.values + 0.023*y_svm.values + 0*y_knn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ensemble = label_ranking_average_precision_score(y_val,ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345250822842396"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Small improvement over sole rf\n",
    "score_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble weight tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All 4 : NN, RF, SVM and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "best_score = 0\n",
    "while i< 200:\n",
    "    \n",
    "    if i%10 ==0:\n",
    "        print(i)\n",
    "        \n",
    "    y_test_nn = np.random.uniform(0.7,1)\n",
    "    y_test_rf = np.random.uniform(0,1-y_test_nn)\n",
    "    y_test_svm = np.random.uniform(0,1-y_test_nn-y_test_rf)\n",
    "    y_test_knn = 1-y_test_nn-y_test_rf-y_test_svm\n",
    "    \n",
    "    \n",
    "    ensemble_score = y_test_nn*y_nn + y_test_rf*y_rf.values + y_test_svm*y_svm.values +y_test_knn*y_knn.values\n",
    "    temp_score = label_ranking_average_precision_score(y_val,ensemble_score)\n",
    "    \n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        \n",
    "        best_weights = []\n",
    "        best_weights.append(y_test_nn)\n",
    "        best_weights.append(y_test_rf)\n",
    "        best_weights.append(y_test_svm)\n",
    "        best_weights.append(y_test_knn)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7484868940173159,\n",
       " 0.12187404054186865,\n",
       " 0.06921964707939315,\n",
       " 0.060419418361422256]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6351116290635036"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "best_score = 0\n",
    "while i< 100:\n",
    "    \n",
    "    if i%10 ==0:\n",
    "        print(i)\n",
    "        \n",
    "    y_test_nn = np.random.uniform(0.4,1)\n",
    "    y_test_rf = 1-y_test_nn\n",
    "    \n",
    "    \n",
    "    ensemble_score = y_test_nn*y_nn + y_test_rf*y_rf.values \n",
    "    temp_score = label_ranking_average_precision_score(y_val,ensemble_score)\n",
    "    \n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        \n",
    "        best_weights = []\n",
    "        best_weights.append(y_test_nn)\n",
    "        best_weights.append(y_test_rf)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6290318995802494"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN, RF and SVM (best combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "best_score = 0\n",
    "while i< 500:\n",
    "    \n",
    "    if i%10 ==0:\n",
    "        print(i)\n",
    "        \n",
    "    y_test_nn = np.random.uniform(0.4,1)\n",
    "    y_test_rf = np.random.uniform(0,1-y_test_nn)\n",
    "    y_test_svm = 1-y_test_nn-y_test_rf    \n",
    "    \n",
    "    ensemble_score = y_test_nn*y_nn + y_test_rf*y_rf.values + y_test_svm*y_svm.values\n",
    "    temp_score = label_ranking_average_precision_score(y_val,ensemble_score)\n",
    "    \n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        \n",
    "        best_weights = []\n",
    "        best_weights.append(y_test_nn)\n",
    "        best_weights.append(y_test_rf)\n",
    "        best_weights.append(y_test_svm)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345056739829807"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8437156989129617, 0.13313503152459621, 0.023149269562442065]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "best_score = 0\n",
    "while i< 100:\n",
    "    \n",
    "    if i%10 ==0:\n",
    "        print(i)\n",
    "        \n",
    "    y_test_nn = np.random.uniform(0.4,1)\n",
    "    y_test_svm = 1-y_test_nn  \n",
    "    \n",
    "    ensemble_score = y_test_nn*y_nn + y_test_svm*y_svm.values\n",
    "    temp_score = label_ranking_average_precision_score(y_val,ensemble_score)\n",
    "    \n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        \n",
    "        best_weights = []\n",
    "        best_weights.append(y_test_nn)\n",
    "        best_weights.append(y_test_svm)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6308784881574803"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
