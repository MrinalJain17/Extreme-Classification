{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- 90% training data, 10% validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13959 examples in training set, and 1552 in validation.\n"
     ]
    }
   ],
   "source": [
    "# Needed to import custom code from other directories\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models import ModifiedMLPClassifier\n",
    "from utils import LRAP\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_FEATURES = 5000\n",
    "NUM_CLASSES = 3993\n",
    "\n",
    "X_train = pd.read_csv(\"../data/expanded/train_features.csv\", names=range(NUM_FEATURES))\n",
    "y_train = pd.read_csv(\"../data/expanded/train_labels.csv\", names=range(NUM_CLASSES))\n",
    "\n",
    "X_valid = pd.read_csv(\"../data/expanded/valid_features.csv\", names=range(NUM_FEATURES))\n",
    "y_valid = pd.read_csv(\"../data/expanded/valid_labels.csv\", names=range(NUM_CLASSES))\n",
    "\n",
    "print(f\"{X_train.shape[0]} examples in training set, and {X_valid.shape[0]} in validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data\n",
    "\n",
    "- Subtracting mean and dividing by variance.\n",
    "- Statistics of training data is used for the validation data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "standardize = StandardScaler()\n",
    "standardize = standardize.fit(X_train)\n",
    "X_train_transformed = standardize.transform(X_train)\n",
    "X_valid_transformed = standardize.transform(X_valid)\n",
    "\n",
    "# X_train_transformed = X_train\n",
    "# X_valid_transformed = X_valid\n",
    "# \n",
    "# normalize = MinMaxScaler()\n",
    "# normalize = normalize.fit(X_train_transformed)\n",
    "# X_train_transformed = normalize.transform(X_train_transformed)\n",
    "# X_valid_transformed = normalize.transform(X_valid_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "While training the multi-layer perceptron, the training and validation loss are reported in each iteration (or epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training loss = 364.64399666\n",
      "Iteration 2, training loss = 48.41153234\n",
      "Iteration 3, training loss = 39.32583581\n",
      "Iteration 4, training loss = 34.96982248\n",
      "Iteration 5, training loss = 32.14490112\n",
      "Iteration 6, training loss = 29.97408445\n",
      "Iteration 7, training loss = 28.15885611\n",
      "Iteration 8, training loss = 26.59237683\n",
      "Iteration 9, training loss = 25.19528590\n",
      "Iteration 10, training loss = 23.95072599\n",
      "Iteration 11, training loss = 22.81576999\n",
      "Iteration 12, training loss = 21.75109183\n",
      "Iteration 13, training loss = 20.78110786\n",
      "Iteration 14, training loss = 19.86857619\n",
      "Iteration 15, training loss = 19.01677641\n",
      "Iteration 16, training loss = 18.22302403\n",
      "Iteration 17, training loss = 17.47301005\n",
      "Iteration 18, training loss = 16.76833762\n",
      "Iteration 19, training loss = 16.11186691\n",
      "Iteration 20, training loss = 15.50234152\n",
      "Iteration 21, training loss = 14.91470869\n",
      "Iteration 22, training loss = 14.35800772\n",
      "Iteration 23, training loss = 13.84645156\n",
      "Iteration 24, training loss = 13.35123457\n",
      "Iteration 25, training loss = 12.88735058\n",
      "Iteration 26, training loss = 12.43523517\n",
      "Iteration 27, training loss = 12.02582342\n",
      "Iteration 28, training loss = 11.63184637\n",
      "Iteration 29, training loss = 11.25959041\n",
      "Iteration 30, training loss = 10.91086438\n",
      "Iteration 31, training loss = inf\n",
      "Iteration 32, training loss = 10.26807739\n",
      "Iteration 33, training loss = 9.95851873\n",
      "Iteration 34, training loss = 9.67093694\n",
      "Iteration 35, training loss = 9.40822302\n",
      "Iteration 36, training loss = 9.16120289\n",
      "Iteration 37, training loss = 8.94522608\n",
      "Iteration 38, training loss = 8.70451179\n",
      "Iteration 39, training loss = 8.51858218\n",
      "Iteration 40, training loss = inf\n",
      "Iteration 41, training loss = 8.13382445\n",
      "Iteration 42, training loss = inf\n",
      "Iteration 43, training loss = 7.74497252\n",
      "Iteration 44, training loss = 7.57240937\n",
      "Iteration 45, training loss = 7.40043810\n",
      "Iteration 46, training loss = 7.26154285\n",
      "Iteration 47, training loss = 7.11443082\n",
      "Iteration 48, training loss = 6.98742951\n",
      "Iteration 49, training loss = inf\n",
      "Iteration 50, training loss = inf\n",
      "Iteration 51, training loss = 6.68581212\n",
      "Iteration 52, training loss = 6.54507923\n",
      "Iteration 53, training loss = 6.42860524\n",
      "Iteration 54, training loss = 6.33377187\n",
      "Iteration 55, training loss = 6.23705625\n",
      "Iteration 56, training loss = 6.15702820\n",
      "Iteration 57, training loss = 6.08522779\n",
      "Iteration 58, training loss = 6.01848363\n",
      "Iteration 59, training loss = 5.99073927\n",
      "Iteration 60, training loss = 5.95116189\n",
      "Iteration 61, training loss = 5.89573458\n",
      "Iteration 62, training loss = 5.86760956\n",
      "Iteration 63, training loss = inf\n",
      "Iteration 64, training loss = inf\n",
      "Iteration 65, training loss = inf\n",
      "Iteration 66, training loss = inf\n",
      "Iteration 67, training loss = inf\n",
      "Iteration 68, training loss = 5.56182727\n",
      "Iteration 69, training loss = inf\n",
      "Iteration 70, training loss = inf\n",
      "Iteration 71, training loss = 5.33272290\n",
      "Iteration 72, training loss = 5.27337382\n",
      "Iteration 73, training loss = inf\n",
      "Iteration 74, training loss = inf\n",
      "Iteration 75, training loss = 5.18046831\n",
      "Iteration 76, training loss = inf\n",
      "Iteration 77, training loss = 5.10690995\n",
      "Iteration 78, training loss = 5.07217447\n",
      "Iteration 79, training loss = 5.04174618\n",
      "Iteration 80, training loss = 5.00952723\n",
      "Iteration 81, training loss = inf\n",
      "Iteration 82, training loss = 4.99974487\n",
      "Iteration 83, training loss = 4.97695814\n",
      "Iteration 84, training loss = 4.97358749\n",
      "Iteration 85, training loss = 5.01186728\n",
      "Iteration 86, training loss = inf\n",
      "Iteration 87, training loss = inf\n",
      "Iteration 88, training loss = inf\n",
      "Iteration 89, training loss = inf\n",
      "Iteration 90, training loss = inf\n",
      "Iteration 91, training loss = inf\n",
      "Iteration 92, training loss = inf\n",
      "Iteration 93, training loss = 4.96722200\n",
      "Iteration 94, training loss = 4.89627767\n",
      "Iteration 95, training loss = inf\n",
      "Iteration 96, training loss = inf\n",
      "Iteration 97, training loss = 4.77712918\n",
      "Iteration 98, training loss = 4.76432477\n",
      "Iteration 99, training loss = 4.73318142\n",
      "Iteration 100, training loss = 4.73423239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../code\\models.py:248: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# Training takes ~10 seconds per iteration\n",
    "mlp = ModifiedMLPClassifier(\n",
    "    hidden_layer_sizes=(256,),\n",
    "    max_iter=100,\n",
    "    alpha=0.1,\n",
    "    verbose=True,\n",
    "    random_state=SEED,\n",
    "    # custom_validation_data=(X_valid_transformed, y_valid)\n",
    ")\n",
    "mlp = mlp.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP on training data: 0.9796\n"
     ]
    }
   ],
   "source": [
    "pred_train = mlp.predict_proba(X_train_transformed)\n",
    "score_train = LRAP(y_train, pred_train)\n",
    "print(f\"LRAP on training data: {score_train:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP on validation data: 0.5246\n"
     ]
    }
   ],
   "source": [
    "pred_valid = mlp.predict_proba(X_valid_transformed)\n",
    "score_valid = LRAP(y_valid, pred_valid)\n",
    "print(f\"LRAP on validation data: {score_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 123\n",
    "sample_pred = mlp.predict(X_valid_transformed[[sample_idx]])[0]\n",
    "actual = y_valid.loc[sample_idx].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([342, 418, 637, 682, 906, 992], dtype=int64),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  88,  128,  342,  637,  992, 1722], dtype=int64),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
