{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13959 examples in training set, and 1552 in validation.\n"
     ]
    }
   ],
   "source": [
    "# Needed to import custom code from other directories\n",
    "import sys\n",
    "sys.path.append('../../code')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models import ModifiedMLPClassifier\n",
    "from utils import LRAP, perfection\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_FEATURES = 5000\n",
    "NUM_CLASSES = 3993\n",
    "\n",
    "X_train = pd.read_csv(\"../../data/expanded/train_features.csv\", names=range(NUM_FEATURES))\n",
    "y_train = pd.read_csv(\"../../data/expanded/train_labels.csv\", names=range(NUM_CLASSES))\n",
    "\n",
    "X_valid = pd.read_csv(\"../../data/expanded/valid_features.csv\", names=range(NUM_FEATURES))\n",
    "y_valid = pd.read_csv(\"../../data/expanded/valid_labels.csv\", names=range(NUM_CLASSES))\n",
    "\n",
    "print(f\"{X_train.shape[0]} examples in training set, and {X_valid.shape[0]} in validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set True to apply log transformation to the features\n",
    "# Intended to be used in combination with one of the other techniques below\n",
    "LOG = True\n",
    "\n",
    "STANDARDIZE = True     # Set True to standardize, False otherwise\n",
    "NORMALIZE = False      # Set True to normalize, False otherwise\n",
    "PCA_COMPONENTS = None  # Set to number of components for PCA (automatically standardized)\n",
    "\n",
    "\n",
    "# ----- Code below applies the transformations as specified ----- #\n",
    "func = []\n",
    "if LOG:\n",
    "    X_train_transformed = np.log1p(X_train.to_numpy())\n",
    "    X_valid_transformed = np.log1p(X_valid.to_numpy())\n",
    "else:\n",
    "    X_train_transformed = X_train.to_numpy()\n",
    "    X_valid_transformed = X_valid.to_numpy()\n",
    "\n",
    "if STANDARDIZE:\n",
    "    func = [StandardScaler()]\n",
    "elif NORMALIZE:\n",
    "    func = [MinMaxScaler()]\n",
    "elif PCA_COMPONENTS is not None:\n",
    "    func = [StandardScaler(with_std=False)]\n",
    "    func.append(PCA(n_components=PCA_COMPONENTS, random_state=SEED))\n",
    "    func.append(StandardScaler(with_mean=False))\n",
    "else:\n",
    "    func = None\n",
    "\n",
    "if func is not None:\n",
    "    for f in func:\n",
    "        f = f.fit(X_train_transformed)\n",
    "        X_train_transformed = f.transform(X_train_transformed)\n",
    "        X_valid_transformed = f.transform(X_valid_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "While training the multi-layer perceptron, the training loss and validation LRAP are reported in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a08151291141f392dee02c1d47d202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 677.75142669\n",
      "Validation score: 0.048437\n",
      "Iteration 2, loss = 82.54380872\n",
      "Validation score: 0.067134\n",
      "Iteration 3, loss = 63.97587383\n",
      "Validation score: 0.107428\n",
      "Iteration 4, loss = 48.84972903\n",
      "Validation score: 0.149965\n",
      "Iteration 5, loss = 40.15930350\n",
      "Validation score: 0.189502\n",
      "Iteration 6, loss = 35.17388524\n",
      "Validation score: 0.220418\n",
      "Iteration 7, loss = 32.04771993\n",
      "Validation score: 0.249521\n",
      "Iteration 8, loss = 29.85018503\n",
      "Validation score: 0.272278\n",
      "Iteration 9, loss = 28.15857928\n",
      "Validation score: 0.297621\n",
      "Iteration 10, loss = 26.71161681\n",
      "Validation score: 0.319205\n",
      "Iteration 11, loss = 25.45974353\n",
      "Validation score: 0.337590\n",
      "Iteration 12, loss = 24.32663647\n",
      "Validation score: 0.358750\n",
      "Iteration 13, loss = 23.30106971\n",
      "Validation score: 0.372639\n",
      "Iteration 14, loss = 22.34775572\n",
      "Validation score: 0.387328\n",
      "Iteration 15, loss = 21.47797844\n",
      "Validation score: 0.402208\n",
      "Iteration 16, loss = 20.66359537\n",
      "Validation score: 0.411926\n",
      "Iteration 17, loss = 19.89646758\n",
      "Validation score: 0.423213\n",
      "Iteration 18, loss = 19.17642378\n",
      "Validation score: 0.434165\n",
      "Iteration 19, loss = 18.49459909\n",
      "Validation score: 0.443698\n",
      "Iteration 20, loss = 17.84451310\n",
      "Validation score: 0.453013\n",
      "Iteration 21, loss = 17.22964989\n",
      "Validation score: 0.461615\n",
      "Iteration 22, loss = 16.64532225\n",
      "Validation score: 0.469174\n",
      "Iteration 23, loss = 16.07970472\n",
      "Validation score: 0.476889\n",
      "Iteration 24, loss = 15.54715984\n",
      "Validation score: 0.480249\n",
      "Iteration 25, loss = 15.02778979\n",
      "Validation score: 0.488922\n",
      "Iteration 26, loss = 14.53072930\n",
      "Validation score: 0.493784\n",
      "Iteration 27, loss = 14.05182994\n",
      "Validation score: 0.498841\n",
      "Iteration 28, loss = 13.59677829\n",
      "Validation score: 0.504186\n",
      "Iteration 29, loss = 13.15889464\n",
      "Validation score: 0.509935\n",
      "Iteration 30, loss = 12.73058048\n",
      "Validation score: 0.514790\n",
      "Iteration 31, loss = 12.32424826\n",
      "Validation score: 0.517947\n",
      "Iteration 32, loss = 11.93215519\n",
      "Validation score: 0.523278\n",
      "Iteration 33, loss = 11.55991318\n",
      "Validation score: 0.526615\n",
      "Iteration 34, loss = 11.19315889\n",
      "Validation score: 0.530914\n",
      "Iteration 35, loss = 10.84348008\n",
      "Validation score: 0.534860\n",
      "Iteration 36, loss = 10.51024090\n",
      "Validation score: 0.538642\n",
      "Iteration 37, loss = 10.17911016\n",
      "Validation score: 0.540958\n",
      "Iteration 38, loss = 9.86742123\n",
      "Validation score: 0.543746\n",
      "Iteration 39, loss = 9.56675736\n",
      "Validation score: 0.545954\n",
      "Iteration 40, loss = 9.27882308\n",
      "Validation score: 0.548559\n",
      "Iteration 41, loss = 9.00860415\n",
      "Validation score: 0.551375\n",
      "Iteration 42, loss = 8.73717869\n",
      "Validation score: 0.552550\n",
      "Iteration 43, loss = 8.48273629\n",
      "Validation score: 0.554545\n",
      "Iteration 44, loss = 8.22880319\n",
      "Validation score: 0.558092\n",
      "Iteration 45, loss = 8.00159970\n",
      "Validation score: 0.560349\n",
      "Iteration 46, loss = 7.77256144\n",
      "Validation score: 0.561554\n",
      "Iteration 47, loss = 7.55078423\n",
      "Validation score: 0.563214\n",
      "Iteration 48, loss = 7.34001769\n",
      "Validation score: 0.563868\n",
      "Iteration 49, loss = 7.13817168\n",
      "Validation score: 0.566295\n",
      "Iteration 50, loss = 6.94384156\n",
      "Validation score: 0.567111\n",
      "Iteration 51, loss = 6.76301164\n",
      "Validation score: 0.568344\n",
      "Iteration 52, loss = 6.58178544\n",
      "Validation score: 0.570015\n",
      "Iteration 53, loss = 6.40357930\n",
      "Validation score: 0.571071\n",
      "Iteration 54, loss = 6.24008905\n",
      "Validation score: 0.572299\n",
      "Iteration 55, loss = 6.08051275\n",
      "Validation score: 0.574498\n",
      "Iteration 56, loss = 5.92383552\n",
      "Validation score: 0.573217\n",
      "Iteration 57, loss = 5.77881511\n",
      "Validation score: 0.574338\n",
      "Iteration 58, loss = 5.64125599\n",
      "Validation score: 0.575354\n",
      "Iteration 59, loss = 5.50058873\n",
      "Validation score: 0.576808\n",
      "Iteration 60, loss = 5.36426654\n",
      "Validation score: 0.575806\n",
      "Iteration 61, loss = 5.24285126\n",
      "Validation score: 0.576866\n",
      "Iteration 62, loss = 5.12380078\n",
      "Validation score: 0.577985\n",
      "Iteration 63, loss = 5.00556984\n",
      "Validation score: 0.577535\n",
      "Iteration 64, loss = 4.89157674\n",
      "Validation score: 0.579492\n",
      "Iteration 65, loss = 4.77951638\n",
      "Validation score: 0.578652\n",
      "Iteration 66, loss = 4.67751355\n",
      "Validation score: 0.578929\n",
      "Iteration 67, loss = 4.57450690\n",
      "Validation score: 0.581143\n",
      "Iteration 68, loss = 4.47219546\n",
      "Validation score: 0.579700\n",
      "Iteration 69, loss = 4.38074761\n",
      "Validation score: 0.581741\n",
      "Iteration 70, loss = 4.29185815\n",
      "Validation score: 0.581153\n",
      "Iteration 71, loss = 4.20175977\n",
      "Validation score: 0.580470\n",
      "Iteration 72, loss = 4.11841848\n",
      "Validation score: 0.581091\n",
      "Iteration 73, loss = 4.03896605\n",
      "Validation score: 0.581902\n",
      "Iteration 74, loss = 3.95715861\n",
      "Validation score: 0.582347\n",
      "Iteration 75, loss = 3.88623756\n",
      "Validation score: 0.582636\n",
      "Iteration 76, loss = 3.81347579\n",
      "Validation score: 0.582384\n",
      "Iteration 77, loss = 3.74123107\n",
      "Validation score: 0.583072\n",
      "Iteration 78, loss = 3.66874764\n",
      "Validation score: 0.583872\n",
      "Iteration 79, loss = 3.60427355\n",
      "Validation score: 0.582740\n",
      "Iteration 80, loss = 3.54530522\n",
      "Validation score: 0.583087\n",
      "Iteration 81, loss = 3.48661232\n",
      "Validation score: 0.582492\n",
      "Iteration 82, loss = 3.42534851\n",
      "Validation score: 0.583899\n",
      "Iteration 83, loss = 3.36299220\n",
      "Validation score: 0.583078\n",
      "Iteration 84, loss = 3.30643929\n",
      "Validation score: 0.583392\n",
      "Iteration 85, loss = 3.25410121\n",
      "Validation score: 0.583064\n",
      "Iteration 86, loss = 3.19936009\n",
      "Validation score: 0.583245\n",
      "Iteration 87, loss = 3.15127145\n",
      "Validation score: 0.583250\n",
      "Iteration 88, loss = 3.10178596\n",
      "Validation score: 0.583534\n",
      "Iteration 89, loss = 3.05546079\n",
      "Validation score: 0.582010\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "mlp = ModifiedMLPClassifier(\n",
    "    hidden_layer_sizes=(512,),\n",
    "    activation=\"relu\",\n",
    "    max_iter=100,\n",
    "    batch_size=800,\n",
    "    alpha=0.2,\n",
    "    early_stopping=True,\n",
    "    verbose=True,\n",
    "    random_state=SEED,\n",
    "    custom_validation_data=(X_valid_transformed, y_valid)\n",
    ")\n",
    "mlp = mlp.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP on training data: 0.9692\n"
     ]
    }
   ],
   "source": [
    "score_train = mlp.score(X_train_transformed, y_train.to_numpy())\n",
    "print(f\"LRAP on training data: {score_train:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP on validation data: 0.5839\n"
     ]
    }
   ],
   "source": [
    "score_valid = mlp.score(X_valid_transformed, y_valid.to_numpy())\n",
    "print(f\"LRAP on validation data: {score_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.479% of examples perfectly predicted\n"
     ]
    }
   ],
   "source": [
    "print(f\"{perfection(y_valid, predictions_valid) * 100:.3f}% of examples perfectly predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 123\n",
    "sample_pred = mlp.predict(X_valid_transformed[[sample_idx]])[0]\n",
    "actual = y_valid.loc[sample_idx].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([342, 418, 637, 682, 906, 992], dtype=int64),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([128, 358, 637, 682, 992], dtype=int64),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
