{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to import custom code from other directories\n",
    "import sys\n",
    "sys.path.append('../../code')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import CSVDataset\n",
    "\n",
    "from utils import LRAP, perfection\n",
    "from train import Net\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_FEATURES = 5000\n",
    "NUM_CLASSES = 3993\n",
    "\n",
    "model_1 = Net.load_from_checkpoint(\"../../code/saved_models/neural_network.ckpt\")\n",
    "model_1.freeze()\n",
    "\n",
    "model_2 = Net.load_from_checkpoint(\"../../code/saved_models/neural_network_2.ckpt\")\n",
    "model_2.freeze()\n",
    "\n",
    "model_3 = Net.load_from_checkpoint(\"../../code/saved_models/neural_network_3.ckpt\")\n",
    "model_3.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = CSVDataset(\n",
    "    \"../../data/expanded/\",\n",
    "    csv_features=\"dev_features.csv\",\n",
    "    csv_labels=\"dev_labels.csv\",\n",
    "    standardize=\"../../code/saved_models/scaler.pkl\",\n",
    ")\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_data, batch_size=model_1.hparams.batch_size\n",
    ")\n",
    "\n",
    "y_valid = pd.read_csv(\"../../data/expanded/dev_labels.csv\", names=range(NUM_CLASSES))\n",
    "y_valid = y_valid.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254337395360583"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1 = []\n",
    "for (features, _) in validation_dataloader:\n",
    "    predictions_1.append(model_1.forward(features))\n",
    "    \n",
    "predictions_1 = torch.cat(predictions_1, dim=0)\n",
    "predictions_1 = torch.sigmoid(predictions_1).numpy()\n",
    "\n",
    "LRAP(y_valid, predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6309594621665222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2 = []\n",
    "for (features, _) in validation_dataloader:\n",
    "    predictions_2.append(model_2.forward(features))\n",
    "    \n",
    "predictions_2 = torch.cat(predictions_2, dim=0)\n",
    "predictions_2 = torch.sigmoid(predictions_2).numpy()\n",
    "\n",
    "LRAP(y_valid, predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6309080790825551"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_3 = []\n",
    "for (features, _) in validation_dataloader:\n",
    "    predictions_3.append(model_3.forward(features))\n",
    "    \n",
    "predictions_3 = torch.cat(predictions_3, dim=0)\n",
    "predictions_3 = torch.sigmoid(predictions_3).numpy()\n",
    "\n",
    "LRAP(y_valid, predictions_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 vs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(beta=0.1) LRAP: 0.6332797202502507\n",
      "(beta=0.15000000000000002) LRAP: 0.6342625478929855\n",
      "(beta=0.20000000000000004) LRAP: 0.6342240855069103\n",
      "(beta=0.25000000000000006) LRAP: 0.6346359196735039\n",
      "(beta=0.30000000000000004) LRAP: 0.6347362352810735\n",
      "(beta=0.3500000000000001) LRAP: 0.634983094385877\n",
      "(beta=0.40000000000000013) LRAP: 0.6347188364623025\n",
      "(beta=0.45000000000000007) LRAP: 0.6343545130373217\n",
      "(beta=0.5000000000000001) LRAP: 0.6337572898431053\n",
      "(beta=0.5500000000000002) LRAP: 0.634080575325971\n",
      "(beta=0.6000000000000002) LRAP: 0.6339205444701758\n",
      "(beta=0.6500000000000001) LRAP: 0.633643227097654\n",
      "(beta=0.7000000000000002) LRAP: 0.6329075556136383\n",
      "(beta=0.7500000000000002) LRAP: 0.6325937474595223\n",
      "(beta=0.8000000000000002) LRAP: 0.631951758906373\n",
      "(beta=0.8500000000000002) LRAP: 0.6307677585567292\n",
      "(beta=0.9000000000000002) LRAP: 0.6292446045849288\n",
      "(beta=0.9500000000000003) LRAP: 0.6276172056163574\n"
     ]
    }
   ],
   "source": [
    "betas =  np.arange(0.1, 1, 0.05)\n",
    "for beta in betas:\n",
    "    ensemble = (beta * predictions_1) + ((1 - beta) * predictions_2)\n",
    "    print(f\"(beta={beta}) LRAP: {LRAP(y_valid, ensemble)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 vs 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(beta=0.1) LRAP: 0.6320920534055976\n",
      "(beta=0.15000000000000002) LRAP: 0.6325836448128798\n",
      "(beta=0.20000000000000004) LRAP: 0.6326709099755596\n",
      "(beta=0.25000000000000006) LRAP: 0.6332985990640884\n",
      "(beta=0.30000000000000004) LRAP: 0.6337515629387955\n",
      "(beta=0.3500000000000001) LRAP: 0.6340260534453079\n",
      "(beta=0.40000000000000013) LRAP: 0.634436934437014\n",
      "(beta=0.45000000000000007) LRAP: 0.6347761277216853\n",
      "(beta=0.5000000000000001) LRAP: 0.6352517050319257\n",
      "(beta=0.5500000000000002) LRAP: 0.6353258684938988\n",
      "(beta=0.6000000000000002) LRAP: 0.6347310765417643\n",
      "(beta=0.6500000000000001) LRAP: 0.6346071826110886\n",
      "(beta=0.7000000000000002) LRAP: 0.6342108177232018\n",
      "(beta=0.7500000000000002) LRAP: 0.6342675331746361\n",
      "(beta=0.8000000000000002) LRAP: 0.6333524526932748\n",
      "(beta=0.8500000000000002) LRAP: 0.633214075564569\n",
      "(beta=0.9000000000000002) LRAP: 0.632705389665642\n",
      "(beta=0.9500000000000003) LRAP: 0.6319769521439863\n"
     ]
    }
   ],
   "source": [
    "betas =  np.arange(0.1, 1, 0.05)\n",
    "for beta in betas:\n",
    "    ensemble = (beta * predictions_2) + ((1 - beta) * predictions_3)\n",
    "    print(f\"(beta={beta}) LRAP: {LRAP(y_valid, ensemble)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 vs 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(beta=0.1) LRAP: 0.6332364366342393\n",
      "(beta=0.15000000000000002) LRAP: 0.6344045670899703\n",
      "(beta=0.20000000000000004) LRAP: 0.6350705649137446\n",
      "(beta=0.25000000000000006) LRAP: 0.6355727511829187\n",
      "(beta=0.30000000000000004) LRAP: 0.6358699459244713\n",
      "(beta=0.3500000000000001) LRAP: 0.6358365378331927\n",
      "(beta=0.40000000000000013) LRAP: 0.6360667906978956\n",
      "(beta=0.45000000000000007) LRAP: 0.6355786985066343\n",
      "(beta=0.5000000000000001) LRAP: 0.6354695449876373\n",
      "(beta=0.5500000000000002) LRAP: 0.635307976867946\n",
      "(beta=0.6000000000000002) LRAP: 0.6344322173711388\n",
      "(beta=0.6500000000000001) LRAP: 0.6341130099221854\n",
      "(beta=0.7000000000000002) LRAP: 0.6332839611061003\n",
      "(beta=0.7500000000000002) LRAP: 0.632207022252148\n",
      "(beta=0.8000000000000002) LRAP: 0.6316344171558514\n",
      "(beta=0.8500000000000002) LRAP: 0.6311327750344585\n",
      "(beta=0.9000000000000002) LRAP: 0.6301826027003959\n",
      "(beta=0.9500000000000003) LRAP: 0.6284259515765099\n"
     ]
    }
   ],
   "source": [
    "betas =  np.arange(0.1, 1, 0.05)\n",
    "for beta in betas:\n",
    "    ensemble = (beta * predictions_1) + ((1 - beta) * predictions_3)\n",
    "    print(f\"(beta={beta}) LRAP: {LRAP(y_valid, ensemble)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 vs 2 vs 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas1 = []\n",
    "betas2 = []\n",
    "betas3 = []\n",
    "for beta1 in np.arange(0.1, 0.9, 0.05):\n",
    "    for beta2 in np.arange(0.1, 1 - beta1, 0.05):\n",
    "        beta3 = 1 - (beta1 + beta2)\n",
    "        betas1.append(beta1)\n",
    "        betas2.append(beta2)\n",
    "        betas3.append(beta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389f4ea42e68499c960b9a4d0d69f88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lraps = []\n",
    "for (b1, b2, b3) in tqdm(zip(betas1, betas2, betas3)):\n",
    "    ensemble = b1 * predictions_1 + b2 * predictions_2 + b3 * predictions_3\n",
    "    lraps.append(LRAP(y_valid, ensemble))\n",
    "    \n",
    "d = {\n",
    "    \"beta_1\": betas1,\n",
    "    \"beta_2\": betas2,\n",
    "    \"beta_3\": betas3,\n",
    "    \"LRAP\": lraps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  beta_1    beta_2    beta_3      LRAP\n",
      "--------  --------  --------  --------\n",
      "    0.1       0.1       0.8   0.634304\n",
      "    0.1       0.15      0.75  0.634577\n",
      "    0.1       0.2       0.7   0.634937\n",
      "    0.1       0.25      0.65  0.635156\n",
      "    0.1       0.3       0.6   0.635765\n",
      "    0.1       0.35      0.55  0.635966\n",
      "    0.1       0.4       0.5   0.636234\n",
      "    0.1       0.45      0.45  0.636523\n",
      "    0.1       0.5       0.4   0.636268\n",
      "    0.1       0.55      0.35  0.636124\n",
      "    0.1       0.6       0.3   0.635614\n",
      "    0.1       0.65      0.25  0.635327\n",
      "    0.1       0.7       0.2   0.634999\n",
      "    0.1       0.75      0.15  0.63452\n",
      "    0.1       0.8       0.1   0.634194\n",
      "    0.1       0.85      0.05  0.633777\n",
      "    0.15      0.1       0.75  0.635303\n",
      "    0.15      0.15      0.7   0.634976\n",
      "    0.15      0.2       0.65  0.63571\n",
      "    0.15      0.25      0.6   0.636342\n",
      "    0.15      0.3       0.55  0.636433\n",
      "    0.15      0.35      0.5   0.636805\n",
      "    0.15      0.4       0.45  0.637043\n",
      "    0.15      0.45      0.4   0.636797\n",
      "    0.15      0.5       0.35  0.636616\n",
      "    0.15      0.55      0.3   0.636267\n",
      "    0.15      0.6       0.25  0.635755\n",
      "    0.15      0.65      0.2   0.635808\n",
      "    0.15      0.7       0.15  0.635259\n",
      "    0.15      0.75      0.1   0.635045\n",
      "    0.15      0.8       0.05  0.635073\n",
      "    0.2       0.1       0.7   0.636071\n",
      "    0.2       0.15      0.65  0.636114\n",
      "    0.2       0.2       0.6   0.636162\n",
      "    0.2       0.25      0.55  0.636485\n",
      "    0.2       0.3       0.5   0.637055\n",
      "    0.2       0.35      0.45  0.637271\n",
      "    0.2       0.4       0.4   0.637215\n",
      "    0.2       0.45      0.35  0.63714\n",
      "    0.2       0.5       0.3   0.63665\n",
      "    0.2       0.55      0.25  0.635998\n",
      "    0.2       0.6       0.2   0.636064\n",
      "    0.2       0.65      0.15  0.635904\n",
      "    0.2       0.7       0.1   0.635262\n",
      "    0.2       0.75      0.05  0.635268\n",
      "    0.25      0.1       0.65  0.636156\n",
      "    0.25      0.15      0.6   0.636374\n",
      "    0.25      0.2       0.55  0.636839\n",
      "    0.25      0.25      0.5   0.636994\n",
      "    0.25      0.3       0.45  0.63714\n",
      "    0.25      0.35      0.4   0.637313\n",
      "    0.25      0.4       0.35  0.637268\n",
      "    0.25      0.45      0.3   0.636717\n",
      "    0.25      0.5       0.25  0.636361\n",
      "    0.25      0.55      0.2   0.636621\n",
      "    0.25      0.6       0.15  0.636322\n",
      "    0.25      0.65      0.1   0.636157\n",
      "    0.25      0.7       0.05  0.635937\n",
      "    0.3       0.1       0.6   0.636559\n",
      "    0.3       0.15      0.55  0.63684\n",
      "    0.3       0.2       0.5   0.637355\n",
      "    0.3       0.25      0.45  0.637126\n",
      "    0.3       0.3       0.4   0.63706\n",
      "    0.3       0.35      0.35  0.636825\n",
      "    0.3       0.4       0.3   0.636434\n",
      "    0.3       0.45      0.25  0.636416\n",
      "    0.3       0.5       0.2   0.63635\n",
      "    0.3       0.55      0.15  0.636159\n",
      "    0.3       0.6       0.1   0.636189\n",
      "    0.3       0.65      0.05  0.635973\n",
      "    0.35      0.1       0.55  0.636823\n",
      "    0.35      0.15      0.5   0.636823\n",
      "    0.35      0.2       0.45  0.637022\n",
      "    0.35      0.25      0.4   0.636896\n",
      "    0.35      0.3       0.35  0.63686\n",
      "    0.35      0.35      0.3   0.636799\n",
      "    0.35      0.4       0.25  0.636308\n",
      "    0.35      0.45      0.2   0.636525\n",
      "    0.35      0.5       0.15  0.636201\n",
      "    0.35      0.55      0.1   0.636144\n",
      "    0.35      0.6       0.05  0.636023\n",
      "    0.4       0.1       0.5   0.636544\n",
      "    0.4       0.15      0.45  0.63644\n",
      "    0.4       0.2       0.4   0.636271\n",
      "    0.4       0.25      0.35  0.636802\n",
      "    0.4       0.3       0.3   0.636813\n",
      "    0.4       0.35      0.25  0.636475\n",
      "    0.4       0.4       0.2   0.636346\n",
      "    0.4       0.45      0.15  0.636472\n",
      "    0.4       0.5       0.1   0.636139\n",
      "    0.4       0.55      0.05  0.635773\n",
      "    0.45      0.1       0.45  0.636212\n",
      "    0.45      0.15      0.4   0.636448\n",
      "    0.45      0.2       0.35  0.636325\n",
      "    0.45      0.25      0.3   0.636438\n",
      "    0.45      0.3       0.25  0.636326\n",
      "    0.45      0.35      0.2   0.636086\n",
      "    0.45      0.4       0.15  0.635856\n",
      "    0.45      0.45      0.1   0.636095\n",
      "    0.45      0.5       0.05  0.635139\n",
      "    0.5       0.1       0.4   0.636014\n",
      "    0.5       0.15      0.35  0.635973\n",
      "    0.5       0.2       0.3   0.63602\n",
      "    0.5       0.25      0.25  0.635769\n",
      "    0.5       0.3       0.2   0.635775\n",
      "    0.5       0.35      0.15  0.635774\n",
      "    0.5       0.4       0.1   0.635527\n",
      "    0.5       0.45      0.05  0.63461\n",
      "    0.55      0.1       0.35  0.635735\n",
      "    0.55      0.15      0.3   0.635641\n",
      "    0.55      0.2       0.25  0.635553\n",
      "    0.55      0.25      0.2   0.635425\n",
      "    0.55      0.3       0.15  0.63529\n",
      "    0.55      0.35      0.1   0.634987\n",
      "    0.55      0.4       0.05  0.634668\n",
      "    0.6       0.1       0.3   0.635219\n",
      "    0.6       0.15      0.25  0.635119\n",
      "    0.6       0.2       0.2   0.635384\n",
      "    0.6       0.25      0.15  0.634802\n",
      "    0.6       0.3       0.1   0.634741\n",
      "    0.6       0.35      0.05  0.63427\n",
      "    0.65      0.1       0.25  0.633989\n",
      "    0.65      0.15      0.2   0.634381\n",
      "    0.65      0.2       0.15  0.634366\n",
      "    0.65      0.25      0.1   0.633939\n",
      "    0.65      0.3       0.05  0.634222\n",
      "    0.7       0.1       0.2   0.633463\n",
      "    0.7       0.15      0.15  0.633411\n",
      "    0.7       0.2       0.1   0.633149\n",
      "    0.7       0.25      0.05  0.633679\n",
      "    0.75      0.1       0.15  0.63283\n",
      "    0.75      0.15      0.1   0.632789\n",
      "    0.75      0.2       0.05  0.633046\n",
      "    0.8       0.1       0.1   0.632462\n",
      "    0.8       0.15      0.05  0.63252\n",
      "    0.85      0.1       0.05  0.63129\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(d, headers=\"keys\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6373549839954993"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lraps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = 0.3 * predictions_1 + 0.2 * predictions_2 + 0.5 * predictions_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions_1).astype(\"float16\").to_csv(\"nn_predictions_1.csv\", index=False, header=False)\n",
    "pd.DataFrame(predictions_2).astype(\"float16\").to_csv(\"nn_predictions_2.csv\", index=False, header=False)\n",
    "pd.DataFrame(predictions_3).astype(\"float16\").to_csv(\"nn_predictions_3.csv\", index=False, header=False)\n",
    "pd.DataFrame(ensemble).astype(\"float16\").to_csv(\"nn_ensemble.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
