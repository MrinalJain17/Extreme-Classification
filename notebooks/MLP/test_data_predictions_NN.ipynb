{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to import custom code from other directories\n",
    "import sys\n",
    "sys.path.append('../../code')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import CSVDataset\n",
    "\n",
    "from utils import LRAP, perfection\n",
    "from train import Net\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_FEATURES = 5000\n",
    "NUM_CLASSES = 3993\n",
    "\n",
    "model = Net.load_from_checkpoint(\"../../code/saved_models/neural_network_combined.ckpt\")\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CSVDataset(\n",
    "    \"../../data/expanded/\",\n",
    "    csv_features=\"test_features.csv\",\n",
    "    csv_labels=None,\n",
    "    standardize=\"../../code/saved_models/scaler_combined.pkl\",\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=model.hparams.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for features in test_dataloader:\n",
    "    predictions.append(model.forward(features))\n",
    "    \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "predictions = torch.sigmoid(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3983</th>\n",
       "      <th>3984</th>\n",
       "      <th>3985</th>\n",
       "      <th>3986</th>\n",
       "      <th>3987</th>\n",
       "      <th>3988</th>\n",
       "      <th>3989</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.676593e-05</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1.042378e-03</td>\n",
       "      <td>0.559985</td>\n",
       "      <td>9.390361e-01</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.799524e-05</td>\n",
       "      <td>4.283153e-05</td>\n",
       "      <td>2.969171e-05</td>\n",
       "      <td>1.629235e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051946e-05</td>\n",
       "      <td>4.275094e-05</td>\n",
       "      <td>4.242583e-05</td>\n",
       "      <td>9.178982e-06</td>\n",
       "      <td>2.670355e-05</td>\n",
       "      <td>1.609088e-05</td>\n",
       "      <td>1.816434e-05</td>\n",
       "      <td>1.420076e-05</td>\n",
       "      <td>1.226968e-05</td>\n",
       "      <td>2.052980e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.399192e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.614214e-06</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>8.402646e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>8.041120e-06</td>\n",
       "      <td>7.867984e-06</td>\n",
       "      <td>8.602236e-06</td>\n",
       "      <td>5.897121e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.765660e-06</td>\n",
       "      <td>7.889398e-06</td>\n",
       "      <td>1.355389e-05</td>\n",
       "      <td>7.217697e-06</td>\n",
       "      <td>6.430950e-06</td>\n",
       "      <td>1.101724e-05</td>\n",
       "      <td>1.122529e-05</td>\n",
       "      <td>3.238719e-06</td>\n",
       "      <td>7.436846e-06</td>\n",
       "      <td>1.418691e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.085931e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.660365e-06</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>4.442814e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>5.919027e-06</td>\n",
       "      <td>4.642799e-06</td>\n",
       "      <td>4.473854e-06</td>\n",
       "      <td>3.044094e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.110882e-06</td>\n",
       "      <td>6.021321e-06</td>\n",
       "      <td>1.828984e-05</td>\n",
       "      <td>6.909427e-06</td>\n",
       "      <td>1.811475e-05</td>\n",
       "      <td>6.964594e-06</td>\n",
       "      <td>5.813019e-06</td>\n",
       "      <td>9.946471e-06</td>\n",
       "      <td>3.944291e-06</td>\n",
       "      <td>6.619838e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.810915e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.729966e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.496302e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.697900e-07</td>\n",
       "      <td>1.056886e-07</td>\n",
       "      <td>4.744740e-09</td>\n",
       "      <td>7.212987e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.491459e-07</td>\n",
       "      <td>6.375414e-08</td>\n",
       "      <td>1.018992e-07</td>\n",
       "      <td>4.881725e-08</td>\n",
       "      <td>3.415880e-08</td>\n",
       "      <td>1.508116e-07</td>\n",
       "      <td>4.523977e-08</td>\n",
       "      <td>1.626262e-08</td>\n",
       "      <td>2.707338e-08</td>\n",
       "      <td>6.945307e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.605153e-04</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.144774e-04</td>\n",
       "      <td>0.295935</td>\n",
       "      <td>5.228910e-05</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>5.944542e-05</td>\n",
       "      <td>2.515619e-05</td>\n",
       "      <td>1.607373e-04</td>\n",
       "      <td>1.139463e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.714389e-04</td>\n",
       "      <td>1.058863e-04</td>\n",
       "      <td>9.241945e-05</td>\n",
       "      <td>8.457553e-05</td>\n",
       "      <td>1.160852e-04</td>\n",
       "      <td>8.715515e-05</td>\n",
       "      <td>9.220537e-05</td>\n",
       "      <td>5.541691e-05</td>\n",
       "      <td>5.935677e-05</td>\n",
       "      <td>1.416644e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>8.439861e-05</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>8.424327e-05</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>2.147939e-05</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>7.354322e-05</td>\n",
       "      <td>5.496506e-05</td>\n",
       "      <td>2.362838e-04</td>\n",
       "      <td>1.990799e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.218937e-05</td>\n",
       "      <td>1.138681e-04</td>\n",
       "      <td>1.083615e-04</td>\n",
       "      <td>6.220916e-05</td>\n",
       "      <td>1.054774e-04</td>\n",
       "      <td>2.216160e-04</td>\n",
       "      <td>1.387955e-04</td>\n",
       "      <td>6.126818e-05</td>\n",
       "      <td>4.370727e-05</td>\n",
       "      <td>5.372788e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>1.269877e-05</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>2.347496e-04</td>\n",
       "      <td>0.234704</td>\n",
       "      <td>1.428709e-04</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5.523857e-05</td>\n",
       "      <td>1.443786e-05</td>\n",
       "      <td>5.857677e-04</td>\n",
       "      <td>1.992908e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665056e-05</td>\n",
       "      <td>2.528906e-05</td>\n",
       "      <td>2.469110e-05</td>\n",
       "      <td>1.181772e-05</td>\n",
       "      <td>4.164413e-05</td>\n",
       "      <td>3.082688e-05</td>\n",
       "      <td>1.375746e-05</td>\n",
       "      <td>2.679876e-05</td>\n",
       "      <td>5.952062e-06</td>\n",
       "      <td>1.158218e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>3.878100e-05</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1.626891e-04</td>\n",
       "      <td>0.694287</td>\n",
       "      <td>1.481197e-04</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>1.355623e-04</td>\n",
       "      <td>6.249922e-05</td>\n",
       "      <td>1.534800e-04</td>\n",
       "      <td>4.560781e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.707761e-05</td>\n",
       "      <td>6.978666e-05</td>\n",
       "      <td>4.826784e-05</td>\n",
       "      <td>1.633807e-05</td>\n",
       "      <td>5.881900e-05</td>\n",
       "      <td>6.162350e-05</td>\n",
       "      <td>5.012642e-05</td>\n",
       "      <td>1.251163e-05</td>\n",
       "      <td>1.847632e-05</td>\n",
       "      <td>1.853488e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>1.472609e-03</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.452970e-05</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1.254621e-05</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>8.582918e-05</td>\n",
       "      <td>1.394587e-05</td>\n",
       "      <td>1.064100e-05</td>\n",
       "      <td>7.261075e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.545609e-04</td>\n",
       "      <td>5.656041e-05</td>\n",
       "      <td>6.027116e-05</td>\n",
       "      <td>1.633823e-04</td>\n",
       "      <td>3.119126e-05</td>\n",
       "      <td>9.800030e-05</td>\n",
       "      <td>8.647631e-05</td>\n",
       "      <td>1.803897e-05</td>\n",
       "      <td>1.224989e-04</td>\n",
       "      <td>2.296242e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>3.207809e-05</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>1.601108e-05</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>3.198172e-05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>4.742290e-05</td>\n",
       "      <td>2.490818e-05</td>\n",
       "      <td>1.012546e-03</td>\n",
       "      <td>3.716646e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.293964e-05</td>\n",
       "      <td>3.744538e-05</td>\n",
       "      <td>7.416629e-05</td>\n",
       "      <td>9.333020e-06</td>\n",
       "      <td>3.543169e-05</td>\n",
       "      <td>4.199932e-05</td>\n",
       "      <td>3.047975e-05</td>\n",
       "      <td>1.303262e-05</td>\n",
       "      <td>1.720540e-05</td>\n",
       "      <td>1.646564e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows × 3993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1             2         3             4         5     \\\n",
       "0     3.676593e-05  0.000112  1.042378e-03  0.559985  9.390361e-01  0.000253   \n",
       "1     6.399192e-06  0.000011  5.614214e-06  0.000106  8.402646e-06  0.000026   \n",
       "2     1.085931e-05  0.000003  6.660365e-06  0.000058  4.442814e-07  0.000014   \n",
       "3     3.810915e-08  0.000001  1.729966e-07  0.000006  2.496302e-05  0.000002   \n",
       "4     2.605153e-04  0.000133  1.144774e-04  0.295935  5.228910e-05  0.000127   \n",
       "...            ...       ...           ...       ...           ...       ...   \n",
       "2484  8.439861e-05  0.000208  8.424327e-05  0.000802  2.147939e-05  0.000067   \n",
       "2485  1.269877e-05  0.000088  2.347496e-04  0.234704  1.428709e-04  0.000015   \n",
       "2486  3.878100e-05  0.000202  1.626891e-04  0.694287  1.481197e-04  0.000061   \n",
       "2487  1.472609e-03  0.000034  1.452970e-05  0.000137  1.254621e-05  0.000707   \n",
       "2488  3.207809e-05  0.000427  1.601108e-05  0.000348  3.198172e-05  0.000042   \n",
       "\n",
       "              6             7             8             9     ...  \\\n",
       "0     1.799524e-05  4.283153e-05  2.969171e-05  1.629235e-04  ...   \n",
       "1     8.041120e-06  7.867984e-06  8.602236e-06  5.897121e-06  ...   \n",
       "2     5.919027e-06  4.642799e-06  4.473854e-06  3.044094e-05  ...   \n",
       "3     1.697900e-07  1.056886e-07  4.744740e-09  7.212987e-08  ...   \n",
       "4     5.944542e-05  2.515619e-05  1.607373e-04  1.139463e-04  ...   \n",
       "...            ...           ...           ...           ...  ...   \n",
       "2484  7.354322e-05  5.496506e-05  2.362838e-04  1.990799e-05  ...   \n",
       "2485  5.523857e-05  1.443786e-05  5.857677e-04  1.992908e-05  ...   \n",
       "2486  1.355623e-04  6.249922e-05  1.534800e-04  4.560781e-05  ...   \n",
       "2487  8.582918e-05  1.394587e-05  1.064100e-05  7.261075e-06  ...   \n",
       "2488  4.742290e-05  2.490818e-05  1.012546e-03  3.716646e-05  ...   \n",
       "\n",
       "              3983          3984          3985          3986          3987  \\\n",
       "0     1.051946e-05  4.275094e-05  4.242583e-05  9.178982e-06  2.670355e-05   \n",
       "1     8.765660e-06  7.889398e-06  1.355389e-05  7.217697e-06  6.430950e-06   \n",
       "2     5.110882e-06  6.021321e-06  1.828984e-05  6.909427e-06  1.811475e-05   \n",
       "3     1.491459e-07  6.375414e-08  1.018992e-07  4.881725e-08  3.415880e-08   \n",
       "4     1.714389e-04  1.058863e-04  9.241945e-05  8.457553e-05  1.160852e-04   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2484  5.218937e-05  1.138681e-04  1.083615e-04  6.220916e-05  1.054774e-04   \n",
       "2485  1.665056e-05  2.528906e-05  2.469110e-05  1.181772e-05  4.164413e-05   \n",
       "2486  2.707761e-05  6.978666e-05  4.826784e-05  1.633807e-05  5.881900e-05   \n",
       "2487  2.545609e-04  5.656041e-05  6.027116e-05  1.633823e-04  3.119126e-05   \n",
       "2488  2.293964e-05  3.744538e-05  7.416629e-05  9.333020e-06  3.543169e-05   \n",
       "\n",
       "              3988          3989          3990          3991          3992  \n",
       "0     1.609088e-05  1.816434e-05  1.420076e-05  1.226968e-05  2.052980e-05  \n",
       "1     1.101724e-05  1.122529e-05  3.238719e-06  7.436846e-06  1.418691e-05  \n",
       "2     6.964594e-06  5.813019e-06  9.946471e-06  3.944291e-06  6.619838e-06  \n",
       "3     1.508116e-07  4.523977e-08  1.626262e-08  2.707338e-08  6.945307e-08  \n",
       "4     8.715515e-05  9.220537e-05  5.541691e-05  5.935677e-05  1.416644e-04  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "2484  2.216160e-04  1.387955e-04  6.126818e-05  4.370727e-05  5.372788e-05  \n",
       "2485  3.082688e-05  1.375746e-05  2.679876e-05  5.952062e-06  1.158218e-05  \n",
       "2486  6.162350e-05  5.012642e-05  1.251163e-05  1.847632e-05  1.853488e-05  \n",
       "2487  9.800030e-05  8.647631e-05  1.803897e-05  1.224989e-04  2.296242e-04  \n",
       "2488  4.199932e-05  3.047975e-05  1.303262e-05  1.720540e-05  1.646564e-05  \n",
       "\n",
       "[2489 rows x 3993 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.astype(\"float16\").to_csv(\"final_test_predictions_nn.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random stuff from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254337395360583"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRAP(y_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1314.000000\n",
       "mean        2.487062\n",
       "std         1.777896\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         4.000000\n",
       "max         9.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_pred = (predictions >= 0.5).astype(\"float\")\n",
    "pd.Series(binary_pred.sum(axis=1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfection(y_valid, binary_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CSVDataset(\n",
    "    \"../../data/expanded/\",\n",
    "    standardize=\"../../code/saved_models/scaler.pkl\",\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=model.hparams.batch_size\n",
    ")\n",
    "\n",
    "y_train = pd.read_csv(\"../../data/expanded/train_labels.csv\", names=range(NUM_CLASSES))\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for (features, labels) in train_dataloader:\n",
    "    predictions.append(model.forward(features))\n",
    "    \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "predictions = torch.sigmoid(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523113911191974"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRAP(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15511.000000\n",
       "mean         4.269937\n",
       "std          1.803299\n",
       "min          0.000000\n",
       "25%          3.000000\n",
       "50%          4.000000\n",
       "75%          6.000000\n",
       "max         18.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_pred = (predictions >= 0.5).astype(\"float\")\n",
    "pd.Series(binary_pred.sum(axis=1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfection(y_train, binary_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1500, random_state=SEED)\n",
    "pca = pca.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reduced = pca.transform(y_train)\n",
    "y_valid_reduced = pca.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = MinMaxScaler()\n",
    "rescale = rescale.fit(y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rescaled = rescale.transform(y_train_reduced)\n",
    "y_valid_rescaled = rescale.transform(y_valid_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pca.inverse_transform(rescale.inverse_transform(y_valid_rescaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp >= 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape[0] * y_valid.shape[1] - (temp == y_valid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP on training data: 0.9692\n"
     ]
    }
   ],
   "source": [
    "score_train = mlp.score(X_train_transformed, y_train.to_numpy())\n",
    "print(f\"LRAP on training data: {score_train:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP on validation data: 0.5839\n"
     ]
    }
   ],
   "source": [
    "score_valid = mlp.score(X_valid_transformed, y_valid.to_numpy())\n",
    "print(f\"LRAP on validation data: {score_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.479% of examples perfectly predicted\n"
     ]
    }
   ],
   "source": [
    "print(f\"{perfection(y_valid, predictions_valid) * 100:.3f}% of examples perfectly predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 123\n",
    "sample_pred = mlp.predict(X_valid_transformed[[sample_idx]])[0]\n",
    "actual = y_valid.loc[sample_idx].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([342, 418, 637, 682, 906, 992], dtype=int64),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([128, 358, 637, 682, 992], dtype=int64),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
